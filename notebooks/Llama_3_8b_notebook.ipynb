{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "import pandas as pd\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"train.csv\"  # Replace with your CSV file path\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Ensure your CSV file has 'text', 'author', and 'id' columns\n",
    "# assert \"text\" in df.columns, \"'text' column not found in CSV file\"\n",
    "# assert \"author\" in df.columns, \"'author' column not found in CSV file\"\n",
    "# assert \"id\" in df.columns, \"'id' column not found in CSV file\"\n",
    "\n",
    "# Convert each row into a Document object\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=row[\"text\"],\n",
    "        metadata={\"author\": row[\"author\"], \"id\": row[\"id\"]}\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'author': 'EAP', 'id': 'id26305'}, page_content='This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=300, chunk_overlap=50)\n",
    "doc_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Use a pre-trained SentenceTransformer model for embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")  # Smaller, fast model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAISS Vectorstore\n",
    "vectorstore = FAISS.from_documents(doc_splits, embedding_model)\n",
    "\n",
    "# Initialize the retrieval chain\n",
    "retriever = vectorstore.as_retriever(serch_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.1\", format=\"json\", temperature=0.2)\n",
    "\n",
    "\n",
    "# Define a prompt template for the classification task\n",
    "classification_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an expert in stylometric analysis. Your task is to predict the author of a given text based on writing style. Consider stylistic features such as word choice, sentence structure, punctuation usage, and overall writing patterns to identify the author.\n",
    "\n",
    "The input text below has a distinct writing style. Using the stylistic features from the text and your knowledge of the authors, classify the text's author.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Here are the authors to choose from: {authors_list}\n",
    "\n",
    "If the text doesn't closely resemble the style of any of the authors above, return \"None\".\n",
    "\n",
    "Answer in the following format:\n",
    "{{\"author\": \"predicted_author_name\"}}\n",
    "\"\"\",\n",
    "    input_variables=[\"text\", \"authors_list\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RAG pipeline for author classification with the prompt template\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",  # Directly using the stuff chain for this example\n",
    "    return_source_documents=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Process workflow to classify the author\n",
    "def classify_author(input_text, authors_list):\n",
    "    # Prepare the input prompt for classification with the list of authors\n",
    "    prompt = classification_prompt.format(text=input_text, authors_list=authors_list)\n",
    "    \n",
    "    # Retrieve relevant context and generate the prediction\n",
    "    prediction = qa_chain.run(prompt)\n",
    "\n",
    "    # Try to parse the result as JSON if it's a string\n",
    "    try:\n",
    "        prediction_dict = json.loads(prediction)\n",
    "    except json.JSONDecodeError:\n",
    "        prediction_dict = {\"author\": prediction}  # If the result is not in JSON format, treat it as a plain string\n",
    "\n",
    "    # Check if the prediction is in the authors list; if not, classify as \"None\"\n",
    "    if prediction_dict[\"author\"] not in authors_list:\n",
    "        prediction_dict[\"author\"] = \"None\"\n",
    "\n",
    "    # Return the predicted author\n",
    "    return prediction_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "authors_list = \", \".join(df[\"author\"].unique())  # List of authors in the dataset\n",
    "\n",
    "sample_text = \"And the children's children, and the newcomers' children, grew up.\"\n",
    "\n",
    "final_prediction = classify_author(sample_text, authors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Author: {'author': 'MWS'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_text = \"The rigging was found to be ill fitted, and greatly strained; and on the third day of the blow, about five in the afternoon, our mizzen mast, in a heavy lurch to windward, went by the board.\"\n",
    "print(f\"Predicted Author: {final_prediction}\")\n",
    "\n",
    "final_prediction = classify_author(sample_text, authors_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Load the test data\n",
    "test_data_path = \"test.csv\"  # Replace with your test CSV file path\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "# List of authors in the dataset\n",
    "authors_list = \", \".join(df[\"author\"].unique())\n",
    "\n",
    "# Predict the author for each text in the test data\n",
    "test_df[\"predicted_author\"] = test_df[\"text\"].apply(lambda x: classify_author(x, authors_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {'author': 'HPL'}\n",
       "1      {'author': 'MWS'}\n",
       "2      {'author': 'EAP'}\n",
       "3      {'author': 'EAP'}\n",
       "4      {'author': 'HPL'}\n",
       "             ...        \n",
       "995    {'author': 'EAP'}\n",
       "996    {'author': 'EAP'}\n",
       "997    {'author': 'MWS'}\n",
       "998    {'author': 'EAP'}\n",
       "999    {'author': 'EAP'}\n",
       "Name: predicted_author, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"predicted_author\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all values in 'predicted_author' strings? True\n"
     ]
    }
   ],
   "source": [
    "test_df['predicted_author'] = test_df['predicted_author'].astype(str)\n",
    "\n",
    "all_strings = test_df['predicted_author'].apply(lambda x: isinstance(x, str)).all()\n",
    "\n",
    "print(\"Are all values in 'predicted_author' strings?\", all_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_author(value):\n",
    "    if isinstance(value, str) and \"'author':\" in value:\n",
    "        match = re.search(r\"'author': '(\\w+)'\", value)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None  # Return None if no match\n",
    "\n",
    "test_df['predicted_author_final'] = test_df['predicted_author'].apply(extract_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      HPL\n",
       "1      MWS\n",
       "2      EAP\n",
       "3      EAP\n",
       "4      HPL\n",
       "      ... \n",
       "995    EAP\n",
       "996    EAP\n",
       "997    MWS\n",
       "998    EAP\n",
       "999    EAP\n",
       "Name: predicted_author_final, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['predicted_author_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.40%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_df[\"author\"],test_df['predicted_author_final'])\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         EAP       0.53      0.62      0.57       390\n",
      "         HPL       0.63      0.51      0.56       280\n",
      "         MWS       0.51      0.49      0.50       330\n",
      "\n",
      "    accuracy                           0.54      1000\n",
      "   macro avg       0.56      0.54      0.54      1000\n",
      "weighted avg       0.55      0.54      0.54      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report\n",
    "\n",
    "print(classification_report(y_pred=test_df['predicted_author'], y_true=test_df['author']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=test_df.drop(columns=['predicted_author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>predicted_author_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id15695</td>\n",
       "      <td>The gigantic magnitude and the immediately ava...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id07954</td>\n",
       "      <td>Shall I disturb this calm by mingling in the w...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id16303</td>\n",
       "      <td>He had seen so many customs and witnessed so g...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id07932</td>\n",
       "      <td>We went up stairs into the chamber where the b...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id20875</td>\n",
       "      <td>Over those horrors the evil moon now hung very...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>id11614</td>\n",
       "      <td>We had been sitting in the dark, and Dupin now...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>id03682</td>\n",
       "      <td>His coat tail is very far longer his pipe, his...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>id15691</td>\n",
       "      <td>As I spoke I fixed my eyes upon his countenanc...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>id21676</td>\n",
       "      <td>On this occasion, my sister was not alone; nor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>id14364</td>\n",
       "      <td>This was not universal.</td>\n",
       "      <td>MWS</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text author  \\\n",
       "0    id15695  The gigantic magnitude and the immediately ava...    EAP   \n",
       "1    id07954  Shall I disturb this calm by mingling in the w...    MWS   \n",
       "2    id16303  He had seen so many customs and witnessed so g...    MWS   \n",
       "3    id07932  We went up stairs into the chamber where the b...    EAP   \n",
       "4    id20875  Over those horrors the evil moon now hung very...    HPL   \n",
       "..       ...                                                ...    ...   \n",
       "995  id11614  We had been sitting in the dark, and Dupin now...    EAP   \n",
       "996  id03682  His coat tail is very far longer his pipe, his...    EAP   \n",
       "997  id15691  As I spoke I fixed my eyes upon his countenanc...    MWS   \n",
       "998  id21676  On this occasion, my sister was not alone; nor...    MWS   \n",
       "999  id14364                            This was not universal.    MWS   \n",
       "\n",
       "    predicted_author_final  \n",
       "0                      HPL  \n",
       "1                      MWS  \n",
       "2                      EAP  \n",
       "3                      EAP  \n",
       "4                      HPL  \n",
       "..                     ...  \n",
       "995                    EAP  \n",
       "996                    EAP  \n",
       "997                    MWS  \n",
       "998                    EAP  \n",
       "999                    EAP  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('test_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
